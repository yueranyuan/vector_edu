\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09
\usepackage[backend=biber]{biblatex}
\bibliography{paper}

\title{Deep learning on psychological arousal classification}


\author{
Yueran Yuan, Jeffrey Zhang, David Rayson, Kai-min Chang\\
Language Technologies Institute\\
Carnegie Mellon University\\
Pittsburgh, PA 15213\\
\texttt{\{yueranyuan, jzhang94, davidr92, kaimin.chang\}@gmail.com}
}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version, comment for submission version!

\begin{document}

\maketitle

\begin{abstract}
We present a task for psychological arousal state classification from EEG data and a model for classifying EEG data using deep learning and ensemble techniques. The task is classification of 10-second recordings taken from Emotiv EPOC headsets into the activities performed during each recording. We find that our model outperforms baseline accuracy values established by random forests and SVMs.
\end{abstract}

\section{Introduction} \label{section:introduction}
One of the ongoing challenges of brain-computer interface (BCI) research is the creation of a non-invasive device that can be directly and accurately controlled with one's mental processes. The most studied approach is electroencephalography (EEG), which is a technique that attaches several electrodes to the scalp to measure the electric potential changes caused by neural oscillations in the brain. EEG devices have been difficult to access for non-researchers until recently, as more EEG headsets become easier to use and available at a lower cost. However, the ability to reliably infer information from the brain using EEG such as intent is limited by poor spatial resolution and susceptibility to noise.

In the last decade, deep learning techniques have made significant advances in machine vision, natural language processing, and speech processing. This success is attributed to the ability of deep neural networks (DNNs) to learn complex and robust distributed representations of inputs \cite{DBLP:journals/corr/abs-1206-5538} when given large numbers of training examples. Because EEG data can be more easily acquired due to the availability of consumer-grade EEG headsets, DNNs present an opportunity for improving performance in BCI. Thus, we developed a deep learning model to classify a constrained set of EEG data.

In section \ref{section:litreview}, we present a detailed discussion of EEG and deep learning. In section \ref{section:data}, we discuss the characteristics of our EEG dataset, features used in EEG signal processing, and the task at hand. In section \ref{section:techniques}, we describe the deep learning and ensemble approaches used in our exploration of the problem. In section \ref{section:experiment}, we describe our experimental setup and evaluation metrics for the task. In section \ref{section:results}, we describe the results we obtained.


\section{Prior work} \label{section:litreview}
\subsection{EEG}
The EEG (electroencephalogram) signal is a voltage signal that can be measured on the surface of the scalp, arising from large areas of coordinated neural activity. Rhythmic fluctuations (oscillation patterns) in the EEG signal occur within several particular frequency bands, and the relative level of activity within each frequency band has been associated with brain/emotional states such as focused attentional processing, engagement, and frustration (Marosi et al., 2002; Marosi et al., 2001;
Mundy-Castle, 1951; Berka et al., 2007) and cognitive and memory performance (Gruber et al., 2004; Fernandez et al., 1998; Gevins et al., 1997; Jensen et al., 2007; Klimesch, 1999). The discriminating power of EEG has been demonstrated in a number of studies, achieving 86\% accuracy on 14-way task discrimination, 95\% accuracy on discriminating high/low memory load (Gevins et al., 1998). 
\subsection{IAPS}
\subsection{Deep Learning}
Contemporary deep learning was introduced relatively recently (Hinton, 2006). Prior to the advent of deep learning, classification algorithms by in large operated on some pre-determined preprocessing steps which transforms the raw input into features. These features were then used by a learning algorithm to train a classifier. Deep algorithms, by contrast, combine data processing and classification in the same learning pipeline. This allows the system to learn how to process raw data from
patterns in the data rather than relying on hand-engineered pre-processing steps. This is why deep learning has alternatively been called feature learning or representation learning.
Deep learning excels when it is trained on large repositories of data. So the relatively recent availability of large datasets for speech, computer vision, and text processing has allowed deep learning researchers to train models matching or beating state-of-the-art systems (Boulanger-Lewandowski et al., 2012; Krizhevsky et al., 2012; Miklov et al., 2011).  Deep learning is particularly good at extracting structure and information from raw data with little to no knowledge about the
nature of the data or the nature of the intended classification task by performing unsupervised pre-training (Mesnil et al., 2012). Researchers hypothesize that this is because deep learning algorithms are able to disentangle the many sources of variation (Bengio, 2009).  This is supported by empirical analysis of the learnt features which demonstrate that features that best distinguish task domains are largely separate from features that best distinguish classification conditions (Glorot et
al., 2011), a separation that suggests features are selectively sensitive to only one type of variation.  The usefulness of this disentanglement is evident in the strong performance of deep learning algorithms in transfer learning competitions (Mesnil et al .,2012; Goodfellow et al., 2011).
Disentangling sources of variation is a particularly useful trait for use in EEG. As mentioned earlier, sources of signal in EEG are not well-understood and feature engineering is very difficult. By providing deep learning algorithms with a sufficiently large EEG dataset, the algorithms may be able to disentangle the many sources of noise and signal to recognize the specific patterns associated with mental states of interest and discarding patterns associated with environmental noise.
Further, deep algorithms excel at transferring between different task domains which may be helpful in creating classifiers that can be used on unseen subjects despite non-trivial differences in subject psychology and physiology.
\subsection{Deep Learning and EEG}
Deep learning has also had some very recent success in non-EEG biometrics and laboratory EEG. Mirowski et al. (2008) used a convolutional neural network on intracranial EEG signal, predicting seizures with zero-false-alarm rate on 20 out of 21 patients, beating SVM and logistic regression. Cecotti and Gr√§ser (2010) achieved state-of-the-art results on detecting the P300 event-related-potential with laboratory grade EEG also using convolutional networks. And more recently, Martinez et al.
(2013) used deep learning techniques to produce models of affect from non-EEG biometrics (Skin Conductance and Blood Volume Pulse) which perform significantly better than ad-hoc feature models.
Uniquely, we are using Deep Learning techniques on non-medical-grade EEG devices to track emotion.

\section{Data} \label{section:data}
Our experiment uses data from Siegle et al. (forthcoming). To our knowledge, this is the largest dataset of EEG collected in controlled laboratory conditions (TODO: get x and n) with n unique subjects from x different sites. The dataset contains various stimuli types and our experiments focus on the IAPS stimuli (TODO: cite lang et al 2008). IAPS is a set of images designed to illicit emotional responses along two emotional axes - high, low arousal and positive, negative valence. The stimuli
fall into 4 categories - low arousal positive valence, low arousal negative valence, high arousal positive valence, and high arousal negative valence. In this dataset, each subject viewed 10 images from each category with a 2 (TODO: check this) second fixation period between each stimulus category. One limitation of the experiment was that the images were shown to the subject in the same sequence.

The data was processed with %TODO: asdfasdfasdf how did siegle process the data??
%TODO: we have big data, oooh. okay maybe not that big but it still takes forever to load 
%-Dataset (details)
% -processing
%-Features
% -raw
% -dtft
%  -windows
% -wavelets
% -other

\section{Techniques} \label{section:techniques}
%TODO: we thought technology x would be a great idea because it has these advantages over the sucky way that one guy was doing it. so we wrote some code and did it. we wrote the code. :o
%-Deep learning
% -deep nets
% -dropout
% -autoencoder
% -denoising autoencoder
% -convolutional neural nets
\subsection{Convolutional Neural Networks}
Convolutional neural networks (CNNs) \cite{DBLP:conf/nips/KrizhevskySH12} are neural networks that are not fully connected: instead, each neuron has a limited field of inputs, which overlaps with the fields of adjacent neurons on its layer.  This technique has found success in image processing, as it mimics the functioning of the human brain's visual cortex.  It has also been applied to EEG analysis \cite{DBLP:journals/pami/CecottiG11}, which we attempt in two different ways.  In the first, time-based convolution, we represent our input sample as a series of time points, each of which consists of a vector of features over several channels; the convolutional neurons' fields consist of overlapping slices of time.  In the second, channel-based convolution, the sample is represented as a series of channels, each of which consists of a vector of data points from that channel over time; the convolutional neurons' fields are sets of channels.  We also use a max-pooling downsampling layer above the convolutional layer; this downsamples the results of the convolution by keeping only the maximum value out of each of a set of non-overlapping regions of the convolutional layer.  Finally, we apply a logistic regression classifier to the results of the downsampling to obtain a classification.
% -parameterized rectifiers
\subsection{Parameterized Rectifiers}
Parameterized rectified linear units (PReLUs) \cite{DBLP:journals/corr/HeZR015} are leaky ReLUs whose slopes are learnable parameters.
% -batchnorm (plus all that other stuff)
\subsection{Batch Normalization}
Batch normalization \cite{DBLP:journals/corr/IoffeS15} is a method for training deep neural networks that makes normalization a part of the network, allowing for better performance and training speed.
%-Ensemble
% -random forest
% -classifier fusion

\section{Experiment} \label{section:experiment}
%TODO: we're not making up numbers here yo.
%-Cross-validation
%-Parameter search
%-Evaluation
% -baseline classifiers
% -auc, acc, best-cutoff
\subsection{Evaluation Metrics}
\subsubsection{Accuracy}
The output of our classifiers when classifying input $x$ into category $A$ or $B$ is two probabilities $P(A_x)$ and $P(B_x)$ (the predicted probability that $x$ is in category $A$ or $B$ respectively), with $P(A_x)+P(B_x)=1$.  We choose the greater of these probabilities and declare its category to be the predicted category for $x$.  The accuracy of the classifier over a set of input samples is then simply the percentage of samples for which the predicted and actual categories agree.
\subsubsection{Best-Cutoff Accuracy}
Best-cutoff accuracy is a generalization of our accuracy calculation described above.  The only change is in how the predicted category for a sample is determined: a cutoff $c$ is set, with the sample declared to be in category $A$ if $P(A_x) > c$ and category $B$ otherwise.  Each time that the best-cutoff accuracy is computed for a set of predictions, the value of the cutoff is dynamically chosen such that the final accuracy result is maximized.
\subsubsection{AUC}
The area under the receiver operating characteristic (ROC) curve has been proposed \cite{DBLP:conf/ijcai/LingHZ03} as a more effective metric for comparing classifiers than accuracy.  The ROC curve represents the ratio of the true positive rate of a classifier to its false positive rate as its discrimination cutoff is varied.  We arbitrarily select one class here to be the positive class and the other to be the negative class.  We then construct a ranking of all input samples from least-likely to most-likely to be in the positive class (as determined by the probability assigned to that class by the classifier).  Our discrimination cutoff is then the point in this ranking list for which we determine less-likely-positive samples to be negative and more-likely ones to be positive.  We calculate the area under the ROC curve over all possible values of this cutoff, using this result as our metric.
%-Alternative evaluations
%-Ranking channels for importance

\section{Results} \label{section:results}
%TODO: yeah so um our thing sucks like the other guy's stuff. but it sucks less. so yaya
%-the results

\section{Conclusion} \label{section:conclusion}
%TODO: look at what we did. we think we can do better next time. but yeah we'll need money for ramen so gib pls
%-refer back to the prev work
%-future work

\section*{Acknowledgments}
%TODO: thanks mom


\printbibliography

\end{document}
